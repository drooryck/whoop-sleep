)
# Step 3: Combine with the original data
daily_workouts <- bind_rows(
daily_workouts,
missing_dates_df
)
# Step 4: Remove any duplicates and sort by date
daily_workouts <- daily_workouts %>%
distinct(Workout.start.date, .keep_all = TRUE) %>%
arrange(Workout.start.date)
# Load necessary libraries
library(ggplot2)
library(reshape2)
# Read the CSV file
sleeps <- read.csv("data/sleeps.csv")
# Select only numeric columns
sleeps_numeric <- sleeps[sapply(sleeps, is.numeric)]
# Compute the correlation matrix using complete observations
cor_matrix2 <- cor(sleeps_numeric, use = "complete.obs")
# Melt the correlation matrix for visualization
melted_cor_matrix2 <- melt(cor_matrix2)
# Create the heatmap using ggplot2
ggplot(melted_cor_matrix2, aes(Var1, Var2, fill = value)) +
geom_tile() +
scale_fill_gradientn(colors = c("blue", "white", "red"), values = c(0, 0.5, 1), limit = c(-1, 1)) +
theme_light(base_size = 14) +
theme(axis.text.x = element_text(angle = 45, hjust = 1),
axis.text.y = element_text(size = 12)) +
labs(title = "Correlation Matrix Heatmap", x = "Variables", y = "Variables") +
theme(plot.title = element_text(hjust = 0.5, size = 16, face = "bold"))
# Define the correlation threshold
threshold <- 0.85
# Find pairs of variables with correlations exceeding the threshold
high_corr_pairs2 <- which(abs(cor_matrix2) > threshold, arr.ind = TRUE)
# Create a data frame of the high-correlation pairs
high_corr_df2 <- data.frame(
Column1 = rownames(cor_matrix2)[high_corr_pairs2[, 1]],
Column2 = colnames(cor_matrix2)[high_corr_pairs2[, 2]],
Correlation = cor_matrix2[high_corr_pairs2]
)
# Remove self-correlations (diagonal elements)
high_corr_df2 <- high_corr_df2[high_corr_df2$Column1 != high_corr_df2$Column2, ]
# Print the high-correlation pairs
print(high_corr_df2)
#Step 1: remove unnecessary or redundant variables
daily_sleep <- sleeps %>%
select(- `Cycle.start.time`,
- `Cycle.end.time`,
- `Cycle.timezone`,
- `Sleep.performance..`,
- `In.bed.duration..min.`,
- `Sleep.efficiency..`,
- `Nap`)
# Step 2: Group by Wake.date and calculate the number of wake-ups and total sleep time
nap_data <- daily_sleep %>%
mutate(Wake.date = as.Date(Wake.onset)) %>%
group_by(Wake.date) %>%
summarise(
Nap.count = n_distinct(Wake.onset) - 1,
Nap.duration = sum(Asleep.duration..min., na.rm = TRUE) - max(Asleep.duration..min.)
) %>%
ungroup() %>%
mutate(Nap.duration = ifelse(Nap.count == 0, 0, Nap.duration))
# Step 3: Group by Wake.onset date and select the row with the largest Asleep.duration..min.
sleep_data <- daily_sleep %>%
# Group by Wake.onset
group_by(as.Date(Wake.onset)) %>%
# Filter to keep the row with the max Asleep.duration..min.
filter(Asleep.duration..min. == max(Asleep.duration..min.)) %>%
slice(1) %>% ungroup()
#Step 4: We will think of your sleep as the day that you worked out
sleep_data <- sleep_data %>%
mutate(Sleep.date = as.Date(Wake.onset) - days(1))
# Step 5: Merge sleep_data and nap_data by their respective date columns
sleep_nap_data <- sleep_data %>%
left_join(nap_data, by = c("Sleep.date" = "Wake.date")) %>%
filter(!is.na(Nap.count))
merged_data <- sleep_nap_data %>%
inner_join(daily_workouts, by = c("Sleep.date" = "Workout.start.date")) %>%
select(-`Sleep.onset`,
- `Wake.onset`,
- `as.Date(Wake.onset)`)
str(merged_data)
# Load necessary libraries
library(dplyr)
# Select the specified variables from merged_data_1
merged_data_1 <- merged_data %>%
select(
-Sleep.date,
-Total.Assault_Bike,
-Total.Cycling,
-Total.Elliptical,
-Total.Functional_Fitness,
-Total.Hiking_Rucking,
-Total.Powerlifting,
-Total.Rowing,
-Total.Running,
-Total.Spin,
-Total.Stairmaster,
-Total.Walking,
-Total.Weightlifting,
-Total.Yoga
)
# Remove rows with missing values
cleaned_data <- na.omit(merged_data_1)
# Basic model, no interaction terms
model <- lm(Deep..SWS..duration..min./Asleep.duration..min. ~ ., data = cleaned_data)
summary(model)$adj.r.squared
plot(model, 1)
plot(model, 2)
# Model with Interactive terms (note this actually has a stronger R^2 than the highly complex model)
model_rr <- lm(Deep..SWS..duration..min./Asleep.duration..min. ~ (Total.Energy.burned.cal)*(.), data = cleaned_data)
summary(model_rr)$adj.r.squared
plot(model_rr, 1)
plot(model_rr, 2)
# highly complex model
model_full <- lm(Deep..SWS..duration..min./Asleep.duration..min. ~ (.)^2, data = cleaned_data)
summary(model_full)$adj.r.squared
plot(model_full, 1)
plot(model_full, 2)
#Originally the model_full was not running on posit - we examined the dataset again and were able to take out more unnecesary values. As a result, we could run step selection on the full model and this gave us a better lowest AIC value (4128.74) than using the interactive term (4197.64)
## Results with Interactive term were:
# Start:  AIC=-4186.2
# Deep..SWS..duration..min./Asleep.duration..min. ~ (Total.Energy.burned.cal) *
#    (Respiratory.rate..rpm. + Nap.count + Nap.duration + Total.Duration.min +
#       Total.Energy.burned.cal + Weighted.Avg.HR + Weighted.Avg.HR.Zone.1 +
#        Weighted.Avg.HR.Zone.2 + Weighted.Avg.HR.Zone.3 + Weighted.Avg.HR.Zone.4 +
#        Weighted.Avg.HR.Zone.5 + Max.HR.bpm + Weighted.Avg.HR.Zone.0)
## Results with full model term were:
# Start:  AIC=-4194.08
# Deep..SWS..duration..min./Asleep.duration..min. ~ (Respiratory.rate..rpm. +
#     Nap.count + Nap.duration + Total.Duration.min + Total.Energy.burned.cal +
#     Weighted.Avg.HR + Weighted.Avg.HR.Zone.1 + Weighted.Avg.HR.Zone.2 +
#     Weighted.Avg.HR.Zone.3 + Weighted.Avg.HR.Zone.4 + Weighted.Avg.HR.Zone.5 +
#     Max.HR.bpm + Weighted.Avg.HR.Zone.0)^2
# Remove rows with missing values
cleaned_data <- na.omit(merged_data_1)
model_backward <- step(model_full, direction = "backward")
colnames(cleaned_data)
model_backward$anova
model_forward$anova
#Step 1: remove unnecessary or redundant variables
daily_sleep <- sleeps %>%
select(- `Cycle.start.time`,
- `Cycle.end.time`,
- `Cycle.timezone`,
- `Sleep.performance..`,
- `In.bed.duration..min.`,
- `Sleep.efficiency..`
- `Sleep.debt..`,
- `Nap`)
options(tinytex.verbose = TRUE)
suppressMessages({
library(ggplot2)
library(reshape2)
library(dplyr)
library(faraway)
library(lubridate)
})
workouts <- read.csv("data/workouts.csv")
workouts_1 <- workouts %>%
select(-`GPS.enabled`,
-`Distance..meters.`,
-`Altitude.gain..meters.`,
-`Altitude.change..meters.`,
- `Cycle.start.time`,
- `Cycle.end.time`,
- `Cycle.timezone`,
- `Workout.start.time`,
- `Workout.end.time`,
- `Activity.name`)
activity_strain <- lm(Activity.Strain ~ ., data = workouts_1)
sumary(activity_strain)
summary(activity_strain)$adj.r.squared
cor_matrix <- cor(workouts_1, use = "complete.obs")
melted_cor_matrix <- melt(cor_matrix)
ggplot(melted_cor_matrix, aes(Var1, Var2, fill = value)) +
geom_tile() +
scale_fill_gradientn(colors = c("blue", "white", "red"), values = c(0, 0.5, 1), limit = c(-1, 1)) +
theme_light(base_size = 14) +
theme(axis.text.x = element_text(angle = 45, hjust = 1),
axis.text.y = element_text(size = 12)) +
labs(title = "Correlation Matrix Heatmap", x = "Variables", y = "Variables") +
theme(plot.title = element_text(hjust = 0.5, size = 16, face = "bold"))
threshold <- 0.85
high_corr_pairs <- which(abs(cor_matrix) > threshold, arr.ind = TRUE)
high_corr_df <- data.frame(
Column1 = rownames(cor_matrix)[high_corr_pairs[, 1]],
Column2 = colnames(cor_matrix)[high_corr_pairs[, 2]],
Correlation = cor_matrix[high_corr_pairs]
)
high_corr_df <- high_corr_df[high_corr_df$Column1 != high_corr_df$Column2, ]
print(high_corr_df)
##note: premise of time series = One Day One Observation
# Step 1: Drop the columns with no data
daily_workouts <- workouts %>%
select(-c("GPS.enabled", "Distance..meters.",
"Altitude.gain..meters.", "Altitude.change..meters."))
# Step 2: Remove the useless or redundant data
daily_workouts <- daily_workouts %>%
select(-c("Cycle.start.time", "Cycle.end.time", "Cycle.timezone"))
# Step 3: Convert Activity.name to a factor
# Note: There was a level in the factor called "Other" with 1 observation,
# which was removed for clarity, since "Other" is no interpretable.
# Note: We also removed the activity "Activity" also for lack of interpretability.
# This activity had 65 observations.
daily_workouts$Activity.name <- as.factor(daily_workouts$Activity.name)
daily_workouts <- daily_workouts %>%
mutate(
Assault_Bike = Activity.name == "Assault Bike",
Cycling = Activity.name == "Cycling",
Elliptical = Activity.name == "Elliptical",
Functional_Fitness = Activity.name == "Functional Fitness",
Hiking_Rucking = Activity.name == "Hiking/Rucking",
Powerlifting = Activity.name == "Powerlifting",
Rowing = Activity.name == "Rowing",
Running = Activity.name == "Running",
Spin = Activity.name == "Spin",
Stairmaster = Activity.name == "Stairmaster",
Walking = Activity.name == "Walking",
Weightlifting = Activity.name == "Weightlifting",
Yoga = Activity.name == "Yoga"
) %>%
select(-Activity.name)  # Remove the original Activity.name column
# Step 4: Convert 'Workout.start.time' to Date and extract the date portion
daily_workouts <- daily_workouts %>%
mutate(Workout.start.date = as.Date(Workout.start.time, format = "%Y-%m-%d %H:%M:%S"))
# Step 5: Group by date and summarize
daily_workouts <- daily_workouts %>%
group_by(Workout.start.date) %>%
summarise(
# Sum of 'Duration..min.' and 'Energy.burned..cal.'
Total.Duration.min = sum(`Duration..min.`, na.rm = TRUE),
Total.Energy.burned.cal = sum(`Energy.burned..cal.`, na.rm = TRUE),
# Weighted average time spent at average heart rate
Weighted.Avg.HR = sum(`Average.HR..bpm.` * `Duration..min.`, na.rm = TRUE) /
sum(`Duration..min.`, na.rm = TRUE),
# Weighted average time spent for heart rate zones
Weighted.Avg.HR.Zone.1 = sum(`HR.Zone.1..` * `Duration..min.`, na.rm = TRUE) /
sum(`Duration..min.`, na.rm = TRUE),
Weighted.Avg.HR.Zone.2 = sum(`HR.Zone.2..` * `Duration..min.`, na.rm = TRUE) /
sum(`Duration..min.`, na.rm = TRUE),
Weighted.Avg.HR.Zone.3 = sum(`HR.Zone.3..` * `Duration..min.`, na.rm = TRUE) /
sum(`Duration..min.`, na.rm = TRUE),
Weighted.Avg.HR.Zone.4 = sum(`HR.Zone.4..` * `Duration..min.`, na.rm = TRUE) /
sum(`Duration..min.`, na.rm = TRUE),
Weighted.Avg.HR.Zone.5 = sum(`HR.Zone.5..` * `Duration..min.`, na.rm = TRUE) /
sum(`Duration..min.`, na.rm = TRUE),
# Keep the Max HR for the day
Max.HR.bpm = max(`Max.HR..bpm.`, na.rm = TRUE),
# Sum of boolean values for each activity (to count the occurrences per day)
Total.Assault_Bike = sum(Assault_Bike, na.rm = TRUE),
Total.Cycling = sum(Cycling, na.rm = TRUE),
Total.Elliptical = sum(Elliptical, na.rm = TRUE),
Total.Functional_Fitness = sum(Functional_Fitness, na.rm = TRUE),
Total.Hiking_Rucking = sum(Hiking_Rucking, na.rm = TRUE),
Total.Powerlifting = sum(Powerlifting, na.rm = TRUE),
Total.Rowing = sum(Rowing, na.rm = TRUE),
Total.Running = sum(Running, na.rm = TRUE),
Total.Spin = sum(Spin, na.rm = TRUE),
Total.Stairmaster = sum(Stairmaster, na.rm = TRUE),
Total.Walking = sum(Walking, na.rm = TRUE),
Total.Weightlifting = sum(Weightlifting, na.rm = TRUE),
Total.Yoga = sum(Yoga, na.rm = TRUE)) %>%
#Create a new column for heart zone 0
mutate(Weighted.Avg.HR.Zone.0 = round((100 - Weighted.Avg.HR.Zone.1 - Weighted.Avg.HR.Zone.2 -
Weighted.Avg.HR.Zone.3 - Weighted.Avg.HR.Zone.4 - Weighted.Avg.HR.Zone.5), 2))
# Step 1: Identify the date range (min and max dates)
date_range <- seq.Date(min(daily_workouts$Workout.start.date),
max(daily_workouts$Workout.start.date), by = "day")
# Step 2: Create a data frame for all dates in the range
missing_dates_df <- data.frame(
Workout.start.date = date_range,
Total.Duration.min = 0,
Total.Energy.burned.cal = 0,
Weighted.Avg.HR = 57,  # Set resting heart rate
Weighted.Avg.HR.Zone.1 = 0,
Weighted.Avg.HR.Zone.2 = 0,
Weighted.Avg.HR.Zone.3 = 0,
Weighted.Avg.HR.Zone.4 = 0,
Weighted.Avg.HR.Zone.5 = 0,
Max.HR.bpm = 57,  # Set resting heart rate for Max HR
Total.Assault_Bike = 0,
Total.Cycling = 0,
Total.Elliptical = 0,
Total.Functional_Fitness = 0,
Total.Hiking_Rucking = 0,
Total.Powerlifting = 0,
Total.Rowing = 0,
Total.Running = 0,
Total.Spin = 0,
Total.Stairmaster = 0,
Total.Walking = 0,
Total.Weightlifting = 0,
Total.Yoga = 0,
Weighted.Avg.HR.Zone.0 = 100  # Set HR Zone 0 to 100
)
# Step 3: Combine with the original data
daily_workouts <- bind_rows(
daily_workouts,
missing_dates_df
)
# Step 4: Remove any duplicates and sort by date
daily_workouts <- daily_workouts %>%
distinct(Workout.start.date, .keep_all = TRUE) %>%
arrange(Workout.start.date)
# Load necessary libraries
library(ggplot2)
library(reshape2)
# Read the CSV file
sleeps <- read.csv("data/sleeps.csv")
# Select only numeric columns
sleeps_numeric <- sleeps[sapply(sleeps, is.numeric)]
# Compute the correlation matrix using complete observations
cor_matrix2 <- cor(sleeps_numeric, use = "complete.obs")
# Melt the correlation matrix for visualization
melted_cor_matrix2 <- melt(cor_matrix2)
# Create the heatmap using ggplot2
ggplot(melted_cor_matrix2, aes(Var1, Var2, fill = value)) +
geom_tile() +
scale_fill_gradientn(colors = c("blue", "white", "red"), values = c(0, 0.5, 1), limit = c(-1, 1)) +
theme_light(base_size = 14) +
theme(axis.text.x = element_text(angle = 45, hjust = 1),
axis.text.y = element_text(size = 12)) +
labs(title = "Correlation Matrix Heatmap", x = "Variables", y = "Variables") +
theme(plot.title = element_text(hjust = 0.5, size = 16, face = "bold"))
# Define the correlation threshold
threshold <- 0.85
# Find pairs of variables with correlations exceeding the threshold
high_corr_pairs2 <- which(abs(cor_matrix2) > threshold, arr.ind = TRUE)
# Create a data frame of the high-correlation pairs
high_corr_df2 <- data.frame(
Column1 = rownames(cor_matrix2)[high_corr_pairs2[, 1]],
Column2 = colnames(cor_matrix2)[high_corr_pairs2[, 2]],
Correlation = cor_matrix2[high_corr_pairs2]
)
# Remove self-correlations (diagonal elements)
high_corr_df2 <- high_corr_df2[high_corr_df2$Column1 != high_corr_df2$Column2, ]
# Print the high-correlation pairs
print(high_corr_df2)
#Step 1: remove unnecessary or redundant variables
daily_sleep <- sleeps %>%
select(- `Cycle.start.time`,
- `Cycle.end.time`,
- `Cycle.timezone`,
- `Sleep.performance..`,
- `In.bed.duration..min.`,
- `Sleep.efficiency..`
- `Sleep.debt..`,
- `Nap`)
colnames(sleeps)
#Step 1: remove unnecessary or redundant variables
daily_sleep <- sleeps %>%
select(- `Cycle.start.time`,
- `Cycle.end.time`,
- `Cycle.timezone`,
- `Sleep.performance..`,
- `In.bed.duration..min.`,
- `Sleep.debt..min.`
- `Sleep.efficiency..`,
- `Nap`)
colnames(sleeps)
#Originally the model_full was not running on posit - we examined the dataset again and were able to take out more unnecesary values. As a result, we could run step selection on the full model and this gave us a better lowest AIC value (4128.74) than using the interactive term (4197.64)
## Results with Interactive term were:
# Start:  AIC=-4186.2
# Deep..SWS..duration..min./Asleep.duration..min. ~ (Total.Energy.burned.cal) *
#    (Respiratory.rate..rpm. + Nap.count + Nap.duration + Total.Duration.min +
#       Total.Energy.burned.cal + Weighted.Avg.HR + Weighted.Avg.HR.Zone.1 +
#        Weighted.Avg.HR.Zone.2 + Weighted.Avg.HR.Zone.3 + Weighted.Avg.HR.Zone.4 +
#        Weighted.Avg.HR.Zone.5 + Max.HR.bpm + Weighted.Avg.HR.Zone.0)
## Results with full model term were:
# Start:  AIC=-4194.08
# Deep..SWS..duration..min./Asleep.duration..min. ~ (Respiratory.rate..rpm. +
#     Nap.count + Nap.duration + Total.Duration.min + Total.Energy.burned.cal +
#     Weighted.Avg.HR + Weighted.Avg.HR.Zone.1 + Weighted.Avg.HR.Zone.2 +
#     Weighted.Avg.HR.Zone.3 + Weighted.Avg.HR.Zone.4 + Weighted.Avg.HR.Zone.5 +
#     Max.HR.bpm + Weighted.Avg.HR.Zone.0)^2
# Remove rows with missing values
cleaned_data <- na.omit(merged_data_1)
model_backward <- step(model_full, direction = "backward")
#Originally the model_full was not running on posit - we examined the dataset again and were able to take out more unnecesary values. As a result, we could run step selection on the full model and this gave us a better lowest AIC value (4128.74) than using the interactive term (4197.64)
## Results with Interactive term were:
# Start:  AIC=-4186.2
## Results with full model term were:
# Start:  AIC=-4194.08
# Remove rows with missing values
cleaned_data <- na.omit(merged_data_1)
model_backward <- step(model_full, direction = "backward")
# Intercept-only model with the cleaned data
model_intercept <- lm(Deep..SWS..duration..min./Asleep.duration..min. ~ 1, data = cleaned_data)
model_forward <- step(model_intercept, direction = "forward", scope = formula(model_full))
colnames(workouts_1)
colnames(cleaned_data)
cleaned_data
# Remove rows with missing values
cleaned_data <- na.omit(merged_data_1)
# Select only numeric columns
cleaned_numeric <- cleaned_data[sapply(cleaned_data, is.numeric)]
# Compute the correlation matrix using complete observations
cor_matrix3 <- cor(cleaned_numeric, use = "complete.obs")
# Melt the correlation matrix for visualization
melted_cor_matrix3 <- melt(cor_matrix3)
# Create the heatmap using ggplot2
library(ggplot2)
library(reshape2)
ggplot(melted_cor_matrix3, aes(Var1, Var2, fill = value)) +
geom_tile() +
scale_fill_gradientn(colors = c("blue", "white", "red"), values = c(0, 0.5, 1), limit = c(-1, 1)) +
theme_light(base_size = 14) +
theme(axis.text.x = element_text(angle = 45, hjust = 1),
axis.text.y = element_text(size = 12)) +
labs(title = "Correlation Matrix Heatmap", x = "Variables", y = "Variables") +
theme(plot.title = element_text(hjust = 0.5, size = 16, face = "bold"))
# Define the correlation threshold
threshold <- 0.85
# Find pairs of variables with correlations exceeding the threshold
high_corr_pairs3 <- which(abs(cor_matrix3) > threshold, arr.ind = TRUE)
# Create a data frame of the high-correlation pairs
high_corr_df3 <- data.frame(
Column1 = rownames(cor_matrix3)[high_corr_pairs3[, 1]],
Column2 = colnames(cor_matrix3)[high_corr_pairs3[, 2]],
Correlation = cor_matrix3[high_corr_pairs3]
)
# Remove self-correlations (diagonal elements)
high_corr_df3 <- high_corr_df3[high_corr_df3$Column1 != high_corr_df3$Column2, ]
# Print the high-correlation pairs
print(high_corr_df3)
# Remove rows with missing values
cleaned_data <- na.omit(merged_data_1)
# Load necessary libraries
library(ggplot2)
library(reshape2)
# Select only numeric columns
cleaned_numeric <- cleaned_data[sapply(cleaned_data, is.numeric)]
# Compute the correlation matrix using complete observations
cor_matrix3 <- cor(cleaned_numeric, use = "complete.obs")
# Melt the correlation matrix for visualization
melted_cor_matrix3 <- melt(cor_matrix3)
# Create the heatmap using ggplot2
heatmap_plot <- ggplot(melted_cor_matrix3, aes(Var1, Var2, fill = value)) +
geom_tile() +
scale_fill_gradientn(colors = c("blue", "white", "red"), values = c(0, 0.5, 1), limit = c(-1, 1)) +
theme_light(base_size = 14) +
theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 12),
axis.text.y = element_text(size = 12)) +
labs(title = "Correlation Matrix Heatmap", x = "Variables", y = "Variables") +
theme(plot.title = element_text(hjust = 0.5, size = 18, face = "bold"))
# Display the plot
print(heatmap_plot)
# Save the plot with increased width and height
ggsave("correlation_matrix_heatmap.png", plot = heatmap_plot, width = 14, height = 12, dpi = 300)
# Remove rows with missing values
cleaned_data <- na.omit(merged_data_1)
# Select only numeric columns
cleaned_numeric <- cleaned_data[sapply(cleaned_data, is.numeric)]
# Compute the correlation matrix using complete observations
cor_matrix3 <- cor(cleaned_numeric, use = "complete.obs")
# Melt the correlation matrix for visualization
melted_cor_matrix3 <- melt(cor_matrix3)
ggplot(melted_cor_matrix3, aes(Var1, Var2, fill = value)) +
geom_tile() +
scale_fill_gradientn(colors = c("blue", "white", "red"), values = c(0, 0.5, 1), limit = c(-1, 1)) +
theme_light(base_size = 14) +
theme(axis.text.x = element_text(angle = 45, hjust = 1),
axis.text.y = element_text(size = 12)) +
labs(title = "Correlation Matrix Heatmap", x = "Variables", y = "Variables") +
theme(plot.title = element_text(hjust = 0.5, size = 16, face = "bold"))
# Define the correlation threshold
threshold <- 0.85
high_corr_pairs3 <- which(abs(cor_matrix3) > threshold, arr.ind = TRUE)
high_corr_df3 <- data.frame(
Column1 = rownames(cor_matrix3)[high_corr_pairs3[, 1]],
Column2 = colnames(cor_matrix3)[high_corr_pairs3[, 2]],
Correlation = cor_matrix3[high_corr_pairs3]
)
high_corr_df3 <- high_corr_df3[high_corr_df3$Column1 != high_corr_df3$Column2, ]
print(high_corr_df3)
colnames(cleaned_data)
model_backward <- step(model_rr, direction = "backward")
# Intercept-only model with the cleaned data
model_intercept <- lm(Deep..SWS..duration..min./Asleep.duration..min. ~ 1, data = cleaned_data)
model_forward <- step(model_intercept, direction = "forward", scope = formula(model_rr))
#Originally the model_full was not running on posit - we examined the dataset again and were able to take out more unnecesary values. As a result, we could run step selection on the full model and this gave us a better lowest AIC value (4128.74) than using the interactive term (4197.64)
## Results with Interactive term were:
# Start:  AIC=-4186.2
## Results with full model term were:
# Start:  AIC=-4295.39
# Remove rows with missing values
cleaned_data <- na.omit(merged_data_1)
model_backward <- step(model_rr, direction = "backward")
# Intercept-only model with the cleaned data
model_intercept <- lm(Deep..SWS..duration..min./Asleep.duration..min. ~ 1, data = cleaned_data)
model_forward <- step(model_intercept, direction = "forward", scope = formula(model_rr))
#Originally the model_full was not running on posit - we examined the dataset again and were able to take out more unnecesary values. As a result, we could run step selection on the full model and this gave us a better lowest AIC value (4128.74) than using the interactive term (4197.64)
## Results with Interactive term were:
# Start:  AIC=-4415.95
## Results with full model term were:
# Start:  AIC=-4295.39
# Remove rows with missing values
cleaned_data <- na.omit(merged_data_1)
model_backward <- step(model_full, direction = "backward")
#Originally the model_full was not running on posit - we examined the dataset again and were able to take out more unnecesary values. As a result, we could run step selection on the full model and this gave us a better lowest AIC value (4128.74) than using the interactive term (4197.64)
## Results with Interactive term were:
# Start:  AIC=-4415.95)
## Results with full model term were:
# Start:  AIC=-4295.39)
# Remove rows with missing values
cleaned_data <- na.omit(merged_data_1)
model_backward <- step(model_rr, direction = "backward")
# Intercept-only model with the cleaned data
model_intercept <- lm(Deep..SWS..duration..min./Asleep.duration..min. ~ 1, data = cleaned_data)
model_forward <- step(model_intercept, direction = "forward", scope = formula(model_rr))
